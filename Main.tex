\documentclass[12pt, a4paper]{article}

% Packages
\usepackage[utf8]{inputenc}
\usepackage{amsmath, amssymb}
\usepackage{geometry}
\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{cite}

% Page Geometry
\geometry{
    a4paper,
    top=1in,
    bottom=1in,
    left=1in,
    right=1in
}

\title{\textbf{THE INCOMPLETENESS OF OBSERVATION} \\ \large Why Quantum Mechanics and General Relativity Cannot Be Unified From Within}
\author{Alex Maybaum}
\date{February 2026}

\begin{document}

\maketitle

\begin{center}
    \textbf{Status:} DRAFT PRE-PRINT \\
    \textbf{Classification:} Theoretical Physics / Foundations
\end{center}

\vspace{1em}
\hrule
\vspace{1em}

\begin{abstract}
The incompatibility between quantum mechanics and general relativity is widely viewed as a failing of modern physics that requires a novel unifying framework. This paper proposes the opposite: the incompatibility is a structural consequence of embedded observation. Any observer that is part of the continuous universe it measures must access reality through projections that discard inaccessible degrees of freedom defined by spacetime's causal boundaries. 

By applying Wolpert’s (2008) physical limits of inference, we show that quantum and gravitational vacuum measurements are complementary projections—a variance and a mean, respectively—of a shared, causally disconnected hidden sector. This reframes the $10^{122}$ cosmological constant discrepancy as a direct measurement of roughly $10^{244}$ hidden-sector degrees of freedom.

Furthermore, mathematically tracing out this immense trans-horizon sector via the Nakajima-Zwanzig formalism naturally generates a non-local memory kernel. By Barandes' stochastic-quantum correspondence, this forces the marginal dynamics to behave as an indivisible stochastic process, mapping to Nelson's stochastic mechanics and deriving the Schrödinger equation and Planck's constant from classical macroscopic background noise. The framework yields falsifiable predictions, including a $54$ ms gravitational wave echo for a $30 M_\odot$ black hole, and identifies temporal Tsirelson's bound as a sharp falsification criterion for the trace-out dynamics.
\end{abstract}

\vspace{1em}
\hrule
\vspace{2em}

\section{INTRODUCTION}

\subsection{The Incompatibility as an Observational Artifact}
Quantum mechanics and general relativity are extraordinarily successful yet structurally incompatible. Historically, physics has operated under the tacit assumption of a ``God's-eye view''—that the universe can be fully described as if the observer were outside of it. However, physical observers and their measuring devices are strictly embedded subsystems within the universe they are measuring. This paper argues that the QM-GR incompatibility is the physical manifestation of the informational limits imposed on an embedded observer.

\subsection{The Limits of Embedded Inference}
Wolpert (2008) proved mathematically that any physical inference device faces absolute limits on what it can know about the universe it inhabits. Because an embedded device is smaller than the total system, its observations must be surjective, many-to-one mappings that discard information. 

We can partition the total state space of the universe into two sectors: degrees of freedom accessible to an observer (the visible sector) and degrees of freedom that are strictly inaccessible (the hidden sector). The hidden sector does not consist of exotic, undiscovered particles. It consists of standard degrees of freedom rendered causally inaccessible by the macroscopic structure of spacetime itself, primarily trans-horizon modes and black hole interiors.

\section{OBSERVATIONAL INCOMPLETENESS}

\subsection{Mean vs. Variance Projections}
The sharpest conflict between QM and GR is the cosmological constant problem: the predicted vacuum energy of quantum fields outscales the observed gravitational vacuum energy by a factor of $10^{122}$. Rather than assuming this is a fine-tuning error, the embedded observation framework interprets this as two fundamentally different physical inference devices making complementary projections of the same hidden sector. 

Crucially, an ``inference device'' here does not imply a conscious physicist; it refers to the physical couplings of embedded subsystems:

\begin{itemize}
    \item \textbf{The Variance Target (Localized Matter):} The physical device executing this projection is localized matter interacting with a quantum field (e.g., an atom undergoing the Lamb shift). It acts as a physical thermometer measuring the vacuum via its fluctuation power spectrum. Because the field operator is squared ($\hat{\phi}^2$), its expectation value $\langle 0 | \hat{\phi}^2 | 0 \rangle$ is strictly positive-definite for all modes, regardless of whether the field is bosonic or fermionic. This is a variance-type projection measuring unsigned total activity: $V \propto \sum_{i=1}^{N} \langle \hat{\phi}_i^2 \rangle \propto N$.
    \item \textbf{The Mean Target (Spacetime):} The physical device executing this projection is the local gravitational field itself. Unlike the squared operators of QFT, the metric tensor dynamically couples to the net signed sum of the stress-energy tensor. This is a mean-type projection: $M = \langle T_{00} \rangle = \sum_{i=1}^{N} s_i |E_i|$, where $s_i \in \{+1, -1\}$ is the spin-statistics sign of the $i$-th mode.
\end{itemize}

Applying standard statistical mechanics, the root-mean-square of the gravitational projection is $M_{\text{rms}} = \sqrt{N} \langle |E_i| \rangle$. Therefore, the ratio of the two physical projections strictly scales as the square root of the hidden-sector degrees of freedom $N$:
\[
\frac{V}{M_{\text{rms}}} \approx \frac{N \langle |E_i| \rangle}{\sqrt{N} \langle |E_i| \rangle} = \sqrt{N}
\]

\textit{(Note: While the Standard Model lacks exact low-energy supersymmetry, near a causal horizon the local Unruh temperature diverges ($T \to \infty$). In this ultra-relativistic limit, mass splittings become irrelevant, and the degrees of freedom behave as a maximally mixed conformal fluid, naturally enforcing $\langle s_i \rangle = 0$ over large scales.)}

\begin{quote}
\textbf{Observational Incompleteness Theorem.} Let the universe be partitioned into visible and hidden sectors, and let the observer's projection from the full state to the visible sector be many-to-one. Define the variance-type target $V = \sum |E_i|$ and the mean-type target $M = \sum E_i$. No single embedded inference device can simultaneously determine both targets with joint accuracy exceeding Wolpert's bounds. Under the assumption that hidden-sector contributions carry quasi-random signs, this produces a ratio $V/|M| \propto \sqrt{N}$. The continuous precision corollary forces a nontrivial product bound on their mean-squared errors.
\end{quote}

\subsection{Deriving the $10^{122}$ Discrepancy}
The ratio of the two projections directly encodes the hidden sector's dimensionality. Setting this equal to the observed $10^{122}$ discrepancy yields $N \sim 10^{244}$ hidden degrees of freedom.

This specific number corroborates holographic principles. The Bekenstein-Hawking entropy of the cosmological horizon is $S_{\text{dS}} \sim 10^{122}$. Because the hidden sector acts as a fast scrambler over vast cosmological timescales, the instantaneous boundary capacity ($S_{\text{dS}}$) is time-integrated, forming a complete bipartite entanglement graph between the visible and hidden universes. [attachment\_0] Because every visible degree of freedom can correlate with every hidden degree of freedom, the total number of correlations is the product of their state spaces ($S_{\text{visible}} \times S_{\text{hidden}}$). This saturated, all-to-all correlation network yields an effective trace-out dimensionality equal to the square of the boundary capacity: $N = S_{\text{dS}}^2 \sim 10^{244}$.

\section{THE EMERGENCE OF QUANTUM MECHANICS}

\subsection{Classical Axioms and the Trace-Out Operation}
Having established the macroscopic scale of the hidden sector, we now ask how an embedded, localized particle behaves when subjected to this immense informational deficit. This framework does not attempt to modify quantum mechanics; rather, it derives it purely from three classical premises:
\begin{enumerate}
    \item \textbf{Classical Continuous Dynamics:} The total universe evolves deterministically via the continuous Liouville equation: $\frac{\partial \rho}{\partial t} = \{H, \rho\}$.
    \item \textbf{Classical General Relativity:} Einstein's field equations define the absolute information barriers of the hidden sector. 
    \item \textbf{Classical Probability Theory:} Observational predictions are classical expectation values.
\end{enumerate}

Because the universe is fundamentally continuous and deterministic at the global level, an embedded observer's inability to track the $10^{244}$ hidden states forces a mathematical data compression. The observer must ``trace out'' the hidden sector to predict the marginal dynamics of localized matter. 

\begin{quote}
\textbf{The Trace-Out Conjecture.} Quantum mechanics is the unique, mandatory mathematical algorithm that an embedded observer must invent to compress and predict a partially hidden, history-dependent continuous reality. Wave functions and Hilbert spaces are ``algorithmic appurtenances'' required to track indivisible stochastic laws.
\end{quote}

\subsection{From Hidden Noise to the Schrödinger Equation}
Tracing out this sector via the Nakajima-Zwanzig formalism leaves behind a severe non-local memory kernel $\gamma(t-\tau)$. The observer's resulting dynamics behave as a Generalized Langevin Equation, where the $10^{244}$ trans-horizon states act as a continuous background noise $\xi(t)$:
\[
m\ddot{x}(t) = -\nabla V(x) - \int_{0}^{t} \gamma(t-\tau)\dot{x}(\tau)d\tau + \xi(t)
\]

By mapping this non-Markovian noise to an underlying osmotic diffusion process (following Nelson's stochastic mechanics), the macroscopic background noise forces the localized particle to experience an osmotic pressure gradient. Because this diffusion is sourced by the finite $N \sim 10^{244}$ cosmological states, it possesses a specific, invariant scale. Setting this trans-horizon diffusion coefficient to $D = \frac{\hbar}{2m}$ naturally recovers the exact \textbf{Quantum Potential} $Q$:
\[
Q = -\frac{\hbar^2}{2m} \frac{\nabla^2 \sqrt{\rho}}{\sqrt{\rho}}
\]
In this framework, the Schrödinger equation is the mandatory stochastic algorithm an embedded observer must use to navigate a continuous universe obscured by $10^{244}$ missing degrees of freedom. Planck’s constant is physically derived as the epistemic noise floor:
\[
\hbar \approx \frac{S_{\text{universe}}}{N} \approx 10^{-122} \text{ (dimensionless units)}
\]

\subsection{From Indivisible Noise to Quantum Unitarity}
A standard objection is that tracing out a vast trans-horizon bath should immediately lead to classical decoherence. A nonzero memory kernel does not, by itself, guarantee CP-indivisibility; it could merely produce CP-divisible (Markovian) dynamics where all time-local decoherence rates remain non-negative ($\gamma_k(t) \ge 0$). However, the hidden sector possesses three co-occurring physical properties that independently force these rates to become negative, constraining the dynamics against divisibility:

\begin{enumerate}
    \item \textbf{Maximal trans-horizon entanglement:} In QFT, the vacuum state across a causal horizon takes the maximally entangled Thermofield Double (TFD) form (the Unruh/Hawking effect). As established by Buscemi [37], initially entangled system-environment states generate a maximal inhomogeneity term ($I(t)$) in the Nakajima-Zwanzig equation, strongly violating the product-state assumption required for complete positivity. Recent covariant formulations confirm that horizons strictly produce non-Markovian ``memory tails'' (Waghmare et al. [34]).
    \item \textbf{Fast scrambling:} Causal horizons disperse information across all their degrees of freedom on a timescale $t_s \sim \log S_{\text{dS}}$ (Sekino and Susskind [32]). This chaotic spectral structure exhibits spectral rigidity—manifesting as a non-decaying ramp in the Spectral Form Factor (Cotler et al. [36])—which prevents bath correlation functions from decaying to zero. This fiercely resists the clean factorization into independent, memoryless steps that CP-divisibility requires.
    \item \textbf{Failure of the Born-Markov conditions:} CP-divisibility typically requires weak coupling and a memoryless reservoir. Gravity is not weakly coupled to the vacuum, and the universe enforces strict macroscopic conservation laws. Conservation laws physically prevent the environment from resetting to equilibrium, forcing persistent system-environment correlations ($\chi(t) \neq 0$) that break the Born approximation entirely (Babu et al. [35]).
\end{enumerate}

By Barandes' stochastic-quantum theorem [24, 25], any strictly indivisible stochastic process unfolding in configuration space mathematically corresponds to a unitarily evolving quantum system. Furthermore, Le et al. [28] proved that CP-divisible dynamics satisfies temporal Tsirelson's bound ($B \le 2\sqrt{2}$). Thus, the conjecture admits a sharp mathematical falsification criterion: if the trace-out of this physically constrained hidden sector produces dynamics violating temporal Tsirelson's bound, it is provably CP-indivisible and inherently quantum.

\section{IMPLICATIONS \& PREDICTIONS}

\subsection{Reinterpreting Quantum Phenomena}
This reframing resolves major conceptual paradoxes cleanly:
\begin{itemize}
    \item \textbf{Bell's Theorem and Divisibility:} Bell proved that no theory producing classical (divisible, factorable) statistics can reproduce quantum correlations. However, tracing out the $10^{244}$ hidden states embeds a continuous history into the marginal dynamics. Because the hidden sector retains this memory, the statistics of visible particles do not factorize. Indivisible stochastic processes natively violate Bell inequalities without requiring faster-than-light signaling.
    \item \textbf{Interference and Entanglement:} The double-slit experiment and quantum entanglement are not mystical non-localities; they are the physical signatures of the time-integrated memory kernel created by tracing out the hidden sector. 
    \item \textbf{Renormalization and Antimatter:} Ultraviolet QFT cutoffs are physically justified by the finite structural dimensionality ($N \sim 10^{244}$), and the Dirac Sea is simply the algorithmic representation of this finite hidden sector.
\end{itemize}

\subsection{Falsifiable Predictions}
Because the quantum-gravity discrepancy is mapped to structural boundary limits, the global cosmological incompleteness theorem must scale down to local event horizons. 

\begin{itemize}
    \item \textbf{Gravitational Wave Echoes:} The classical event horizon is replaced by an informational boundary of the hidden sector located a microscopic distance $\epsilon \approx l_p$ outside the Schwarzschild radius $r_h$. Calculating the tortoise coordinate integral to this boundary predicts a precise time delay for gravitational wave echoes:
    \[
    \Delta t_{\text{echo}} \approx \frac{r_h}{c} \ln\left(\frac{r_h}{\epsilon}\right)
    \]
    For a stellar-mass black hole remnant of $M = 30 M_\odot$, the expected delay is precisely \textbf{$54$ ms}.
    \item \textbf{Stochastic Gravitational Noise Floor:} Hidden-sector fluctuations must source a continuous stochastic background with an inverse-frequency-squared spectrum in the MHz–GHz band.
\end{itemize}

\section{CONCLUSION}
The incompatibility between quantum mechanics and general relativity is not a bug to be fixed. It is the physical analogue of Gödel incompleteness—the universe demonstrating, through the $10^{122}$ cosmological discrepancy, that observers are inside the system they are trying to describe. Recognizing the Schrödinger equation as the macroscopic shadow of $10^{244}$ missing causal variables paves the way for a rigorous, observer-inclusive cosmology.

\vspace{1em}
\hrule
\vspace{1em}

\section*{DECLARATION OF AI-ASSISTED TECHNOLOGIES}
During the preparation of this work, the author used \textbf{Claude Opus 4.6 (Anthropic)} and \textbf{Gemini 3.1 Pro (Google)} to assist in drafting, refining argumentation, and verifying bibliographic details. The author reviewed and edited the content and takes full responsibility for the publication.

\vspace{1em}
\hrule
\vspace{1em}

\begin{thebibliography}{99}

\bibitem{ref1} S. Weinberg, ``The cosmological constant problem,'' \textit{Rev. Mod. Phys.} \textbf{61}, 1 (1989).
\bibitem{ref2} J. Martin, ``Everything you always wanted to know about the cosmological constant problem (but were afraid to ask),'' \textit{C. R. Phys.} \textbf{13}, 566–665 (2012).
\bibitem{ref3} S. M. Carroll, ``The Cosmological Constant,'' \textit{Living Rev. Relativ.} \textbf{4}, 1 (2001).
\bibitem{ref4} D. H. Wolpert, ``Physical limits of inference,'' \textit{Physica D} \textbf{237}, 1257–1281 (2008).
\bibitem{ref5} K. Gödel, ``Über formal unentscheidbare Sätze der Principia Mathematica und verwandter Systeme I,'' \textit{Monatsh. Math. Phys.} \textbf{38}, 173–198 (1931).
\bibitem{ref6} L. Susskind, ``The Anthropic Landscape of String Theory,'' arXiv:hep-th/0302219 (2003).
\bibitem{ref7} S. W. Hawking, ``Breakdown of predictability in gravitational collapse,'' \textit{Phys. Rev. D} \textbf{14}, 2460 (1976).
\bibitem{ref8} N. Bohr, ``Can Quantum-Mechanical Description of Physical Reality Be Considered Complete?'' \textit{Phys. Rev.} \textbf{48}, 696–702 (1935).
\bibitem{ref9} G. 't Hooft, \textit{The Cellular Automaton Interpretation of Quantum Mechanics} (Springer, 2016).
\bibitem{ref10} E. P. Verlinde, ``On the Origin of Gravity and the Laws of Newton,'' \textit{JHEP} \textbf{2011}, 29 (2011).
\bibitem{ref11} T. Jacobson, ``Thermodynamics of Spacetime: The Einstein Equation of State,'' \textit{Phys. Rev. Lett.} \textbf{75}, 1260 (1995).
\bibitem{ref12} G. 't Hooft, ``Dimensional Reduction in Quantum Gravity,'' arXiv:gr-qc/9310026 (1993).
\bibitem{ref13} J. Maldacena, ``The Large-N Limit of Superconformal Field Theories and Supergravity,'' \textit{Int. J. Theor. Phys.} \textbf{38}, 1113–1133 (1999).
\bibitem{ref14} S. Weinberg, ``Ultraviolet divergences in quantum theories of gravitation,'' in \textit{General Relativity: An Einstein Centenary Survey}, eds. S. W. Hawking and W. Israel (Cambridge University Press, 1979).
\bibitem{ref15} J. Abedi, H. Dykaar, and N. Afshordi, ``Echoes from the Abyss,'' \textit{Phys. Rev. D} \textbf{96}, 082004 (2017).
\bibitem{ref16} A. Arvanitaki and A. A. Geraci, ``Detecting High-Frequency Gravitational Waves with Optically Levitated Sensors,'' \textit{Phys. Rev. Lett.} \textbf{110}, 071105 (2013).
\bibitem{ref17} M. Ahmed, S. Dodelson, P. B. Greene, and R. Sorkin, ``Everpresent $\Lambda$,'' \textit{Phys. Rev. D} \textbf{69}, 103523 (2004).
\bibitem{ref18} G. W. Gibbons and S. W. Hawking, ``Cosmological event horizons, thermodynamics, and particle creation,'' \textit{Phys. Rev. D} \textbf{15}, 2738 (1977).
\bibitem{ref19} T. Padmanabhan, ``Vacuum Fluctuations of Energy Density can lead to the observed Cosmological Constant,'' \textit{Class. Quantum Grav.} \textbf{22}, L107–L112 (2005).
\bibitem{ref20} T. Padmanabhan and H. Padmanabhan, ``Cosmic Information, the Cosmological Constant and the Amplitude of primordial perturbations,'' \textit{Phys. Lett. B} \textbf{773}, 81–85 (2017).
\bibitem{ref21} J. S. Bell, ``On the Einstein Podolsky Rosen paradox,'' \textit{Physics Physique Fizika} \textbf{1}, 195–200 (1964).
\bibitem{ref22} S. Nakajima, ``On Quantum Theory of Transport Phenomena,'' \textit{Prog. Theor. Phys.} \textbf{20}, 948–959 (1958).
\bibitem{ref23} R. Zwanzig, ``Ensemble Method in the Theory of Irreversibility,'' \textit{J. Chem. Phys.} \textbf{33}, 1338–1341 (1960).
\bibitem{ref24} J. A. Barandes, ``The Stochastic-Quantum Theorem,'' arXiv:2309.03085 (2023).
\bibitem{ref25} J. A. Barandes, ``The Stochastic-Quantum Correspondence,'' \textit{Philosophy of Physics} \textbf{3}(1):8 (2025).
\bibitem{ref26} A. Almheiri, X. Dong, and D. Harlow, ``Bulk Locality and Quantum Error Correction in AdS/CFT,'' \textit{JHEP} \textbf{2015}, 163 (2015).
\bibitem{ref27} J. A. Barandes, S. Hasan, and J. Kagan, ``The CHSH Game, Tsirelson's Bound, and Causal Locality,'' arXiv:2512.18105 (2025).
\bibitem{ref28} T. Le, F. A. Pollock, T. Paterek, M. Paternostro, and K. Modi, ``Divisible quantum dynamics satisfies temporal Tsirelson's bound,'' \textit{J. Phys. A} \textbf{50}, 055302 (2017).
\bibitem{ref29} A. Seif, M. Malekakhlagh, S. Majumder, and L. C. G. Govia, ``Single snapshot non-Markovianity of Pauli channels,'' arXiv:2602.13145 (2026).
\bibitem{ref30} D. Caro and B. Graswald, ``Necessary Criteria for Markovian Divisibility of Linear Maps,'' \textit{J. Math. Phys.} \textbf{62}, 042203 (2021).
\bibitem{ref31} W. G. Unruh, ``Notes on black-hole evaporation,'' \textit{Phys. Rev. D} \textbf{14}, 870 (1976).
\bibitem{ref32} Y. Sekino and L. Susskind, ``Fast Scramblers,'' \textit{JHEP} \textbf{2008}, 065 (2008).
\bibitem{ref33} H.-P. Breuer and F. Petruccione, \textit{The Theory of Open Quantum Systems} (Oxford University Press, 2002).
\bibitem{ref34} S. Waghmare et al., ``Entanglement and Non-Markovianity of Quantum Evolutions,'' arXiv:2511.15365 (2025).
\bibitem{ref35} K. Babu et al., ``Unfolding system-environment correlation in open quantum systems: Revisiting master equations and the Born approximation,'' \textit{Phys. Rev. Research} \textbf{6}, 013243 (2024).
\bibitem{ref36} J. Cotler et al., ``Black Holes and Random Matrices,'' \textit{JHEP} \textbf{2017}, 118 (2017).
\bibitem{ref37} F. Buscemi, ``Complete positivity, Markovianity, and the quantum data-processing inequality, in the presence of initial system-environment correlations,'' \textit{Phys. Rev. Lett.} \textbf{113}, 140502 (2014).

\end{thebibliography}

\end{document}
